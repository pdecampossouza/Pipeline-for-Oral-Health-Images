# -*- coding: utf-8 -*-
# Streamlit dashboard to browse dataset artifacts generated by the unsupervised_kit
# Usage:
#   streamlit run unsupervised_kit/dashboard.py -- --root "."
#
# UI text is in English (paper-friendly). The app reads artifacts in metadata/.

from pathlib import Path
import argparse
import io
import re
from typing import Optional, Dict, Any, List

import numpy as np
import pandas as pd
import streamlit as st
from PIL import Image


# ----------------- CLI -----------------
def parse_args():
    ap = argparse.ArgumentParser()
    ap.add_argument(
        "--root",
        default=".",
        help="Project root (contains metadata/ and image folders)",
    )
    return ap.parse_args()


# ----------------- Helpers -----------------
@st.cache_data(show_spinner=False)
def load_artifacts(root: Path) -> Dict[str, Any]:
    meta = root / "metadata"
    man = pd.read_csv(meta / "manifest.csv")

    clusters = (
        pd.read_csv(meta / "clusters.csv") if (meta / "clusters.csv").exists() else None
    )
    views = pd.read_csv(meta / "views.csv") if (meta / "views.csv").exists() else None

    # optional reports
    rpt_counts = meta / "report_counts_by_dataset_cluster.csv"
    rpt_vol = meta / "report_counts_by_dataset_volunteer.csv"
    rpt_comp = meta / "report_cluster_compactness.csv"
    rpt_sim = meta / "report_embedding_similarity.csv"

    reports = {
        "counts_by_dataset_cluster": (
            pd.read_csv(rpt_counts) if rpt_counts.exists() else None
        ),
        "counts_by_dataset_volunteer": (
            pd.read_csv(rpt_vol) if rpt_vol.exists() else None
        ),
        "cluster_compactness": pd.read_csv(rpt_comp) if rpt_comp.exists() else None,
        "embedding_similarity": pd.read_csv(rpt_sim) if rpt_sim.exists() else None,
    }

    # figures
    pca_global = meta / "clusters_pca.png"
    pca_per = sorted(meta.glob("clusters_pca__*.png"))
    conf = meta / "view_confusion_matrix.png"
    mis_html = meta / "misclassified.html"
    logo_path = meta / "logo.png"  # optional

    return {
        "manifest": man,
        "clusters": clusters,
        "views": views,
        "reports": reports,
        "pca_global": pca_global if pca_global.exists() else None,
        "pca_per": pca_per,
        "confusion": conf if conf.exists() else None,
        "mis_html": mis_html if mis_html.exists() else None,
        "meta_dir": meta,
        "root": root,
        "logo": logo_path if logo_path.exists() else None,
    }


def df_to_bytes(df: pd.DataFrame) -> bytes:
    buf = io.StringIO()
    df.to_csv(buf, index=False)
    return buf.getvalue().encode("utf-8")


def find_existing_image(root: Path, relpath: str) -> Optional[Path]:
    """
    Try several strategies to find an image on disk:
    - root / relpath (as-is)
    - normalized slashes
    - fallback: search by basename anywhere under root
    """
    p = (root / relpath).resolve()
    if p.exists():
        return p
    rel2 = str(relpath).replace("\\", "/")
    p2 = (root / rel2).resolve()
    if p2.exists():
        return p2
    base = Path(relpath).name
    matches = list(root.rglob(base))
    if matches:
        return matches[0]
    return None


def load_image_safe(p: Path) -> Optional[Image.Image]:
    try:
        return Image.open(p)
    except Exception:
        return None


# ----------------- App -----------------
def main():
    st.set_page_config(
        page_title="SBBrasil TrainSheets — Dataset Dashboard", layout="wide"
    )

    # ---------- CSS & Header ----------
    st.markdown(
        """
    <style>
    /* Hide Streamlit default menu & footer (optional) */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}

    .block-container {max-width: 1320px; padding-top: 0.8rem;}

    .header {
      background: linear-gradient(135deg,#0f172a 0%,#111827 60%,#0b1320 100%);
      color: #e5e7eb; border: 1px solid #1f2937;
      border-radius: 14px; padding: 20px 24px; margin: 8px 0 18px 0;
    }
    .header h1 {margin: 0 0 6px 0; font-size: 34px; letter-spacing: .2px;}
    .header p  {margin: 0; opacity: .85;}
    .kpis {display:flex; gap:22px; margin-top:12px; flex-wrap:wrap}
    .kpi {background:#0b1224;border:1px solid #1f2937;border-radius:12px;padding:10px 14px;color:#d1d5db}
    .kpi .v {font-weight:600;font-size:18px}
    .kpi .k {font-size:12px;opacity:.8}
    .badge {font-size:12px;background:#eef2ff;color:#1f2937;padding:2px 8px;border-radius:999px;border:1px solid #c7d2fe}
    .caption {font-size:12px;color:#6b7280}
    </style>
    """,
        unsafe_allow_html=True,
    )

    args = parse_args()
    ROOT = Path(args.root).resolve()
    data = load_artifacts(ROOT)

    n_imgs = len(data["manifest"])
    n_pdfs = data["manifest"]["pdf_base"].nunique()
    has_views = data["views"] is not None
    has_conf = data["confusion"] is not None

    left, right = st.columns([0.78, 0.22])
    with left:
        st.markdown(
            f"""
        <div class="header">
          <h1>SBBrasil TrainSheets — Dataset Dashboard</h1>
          <p>Curated images extracted from public training manuals, with metadata, weak labels and baseline analyses.</p>
          <div class="kpis">
            <div class="kpi"><div class="v">{n_imgs}</div><div class="k">Images</div></div>
            <div class="kpi"><div class="v">{n_pdfs}</div><div class="k">Modules (PDFs)</div></div>
            <div class="kpi"><div class="v">{'Yes' if has_views else 'No'}</div><div class="k">Views CSV</div></div>
            <div class="kpi"><div class="v">{'Yes' if has_conf else 'No'}</div><div class="k">Confusion Matrix</div></div>
          </div>
        </div>
        """,
            unsafe_allow_html=True,
        )
    with right:
        if data["logo"] is not None:
            st.image(load_image_safe(data["logo"]), use_container_width=True)

    # ---------- Sidebar ----------
    st.sidebar.header("Artifacts")
    st.sidebar.write(f"**Root:** `{ROOT}`")
    st.sidebar.write(f"**metadata/** exists: {data['meta_dir'].exists()}")
    st.sidebar.caption("All tables/figures are generated by your pipeline.")

    # Downloads (CSV buttons)
    st.sidebar.subheader("Download CSVs")
    st.sidebar.download_button(
        "manifest.csv", df_to_bytes(data["manifest"]), "manifest.csv", "text/csv"
    )
    if data["views"] is not None:
        st.sidebar.download_button(
            "views.csv", df_to_bytes(data["views"]), "views.csv", "text/csv"
        )
    if data["clusters"] is not None:
        st.sidebar.download_button(
            "clusters.csv", df_to_bytes(data["clusters"]), "clusters.csv", "text/csv"
        )
    for key, label in [
        ("counts_by_dataset_cluster", "report_counts_by_dataset_cluster.csv"),
        ("counts_by_dataset_volunteer", "report_counts_by_dataset_volunteer.csv"),
        ("cluster_compactness", "report_cluster_compactness.csv"),
        ("embedding_similarity", "report_embedding_similarity.csv"),
    ]:
        df = data["reports"].get(key)
        if df is not None:
            st.sidebar.download_button(label, df_to_bytes(df), label, "text/csv")

    # ---------- Overview ----------
    st.subheader("Overview")
    man = data["manifest"]
    st.markdown(
        f"- **Images:** {n_imgs}  \n"
        f"- **Modules (PDFs):** {n_pdfs}  \n"
        f"- **Columns in manifest:** `{list(man.columns)}`"
    )

    colA, colB = st.columns(2)
    with colA:
        if data["reports"]["counts_by_dataset_cluster"] is not None:
            st.markdown("**Counts by dataset & cluster**")
            st.dataframe(
                data["reports"]["counts_by_dataset_cluster"], use_container_width=True
            )
    with colB:
        if data["reports"]["counts_by_dataset_volunteer"] is not None:
            st.markdown("**Counts by dataset & volunteer**")
            st.dataframe(
                data["reports"]["counts_by_dataset_volunteer"], use_container_width=True
            )

    # ---------- Dataset Browser ----------
    st.subheader("Dataset Browser")

    # optional regex filter for pdf_base
    regex = st.text_input("Filter modules by regex (applied to `pdf_base`)", value="")
    pdfs_all: List[str] = sorted(man["pdf_base"].unique())
    if regex:
        pdfs = [
            p
            for p in pdfs_all
            if pd.Series([p]).str.contains(regex, regex=True).iloc[0]
        ]
    else:
        pdfs = pdfs_all

    sel_pdf = st.selectbox(
        "Select a module (pdf_base)", pdfs, index=0 if pdfs else None
    )
    if sel_pdf:
        df_pdf = (
            man[man["pdf_base"] == sel_pdf].copy().sort_values(["voluntario", "seq"])
        )
        st.markdown(f"**Rows:** {len(df_pdf)}")
        st.dataframe(df_pdf, use_container_width=True, height=320)

        # Thumbnails (deduplicated)
        n_thumbs = st.slider("Number of sample thumbnails", 6, 48, 12, step=6)
        dedup_mode = st.selectbox(
            "Deduplication mode",
            ["by filename (recommended)", "by (volunteer, seq)", "none"],
            index=0,
        )

        df_show = df_pdf.copy()
        if dedup_mode == "by filename (recommended)":
            df_show["fname"] = df_show["filepath"].apply(lambda s: Path(str(s)).name)
            df_show = df_show.drop_duplicates(subset=["fname"])
        elif dedup_mode == "by (volunteer, seq)":
            df_show = df_show.drop_duplicates(subset=["voluntario", "seq"])
        # shuffle for variety
        df_show = df_show.sample(frac=1.0, random_state=42)

        st.markdown("**Sample images from the selected module**")
        cols = st.columns(6)
        for i, (_, row) in enumerate(df_show.head(n_thumbs).iterrows()):
            found = find_existing_image(ROOT, str(row["filepath"]))
            with cols[i % 6]:
                if found:
                    img = load_image_safe(found)
                    if img:
                        st.image(
                            img,
                            caption=str(found.relative_to(ROOT)),
                            use_container_width=True,
                        )
                    else:
                        st.caption(f"(cannot open) {found}")
                else:
                    st.caption(f"(missing) {row['filepath']}")
    else:
        st.info("No modules matched your regex filter.")

    # ---------- Views & Clusters ----------
    st.subheader("Views & Clusters")
    c1, c2 = st.columns(2)
    with c1:
        if data["clusters"] is not None:
            st.markdown("**clusters.csv (head)**")
            st.dataframe(
                data["clusters"].head(20), use_container_width=True, height=260
            )
    with c2:
        if data["views"] is not None:
            st.markdown("**views.csv (head)**")
            st.dataframe(data["views"].head(20), use_container_width=True, height=260)

    # ---------- Figures ----------
    st.subheader("Figures")
    col1, col2 = st.columns(2)
    with col1:
        if data["pca_global"] is not None:
            img = load_image_safe(data["pca_global"])
            if img:
                st.image(
                    img,
                    caption="PCA of features — colored by cluster",
                    use_container_width=True,
                )
    with col2:
        if data["confusion"] is not None:
            img = load_image_safe(data["confusion"])
            if img:
                st.image(
                    img,
                    caption="View classification — Confusion matrix",
                    use_container_width=True,
                )

    st.markdown("**PCA per dataset**")
    if data["pca_per"]:
        cols = st.columns(3)
        for i, p in enumerate(data["pca_per"]):
            img = load_image_safe(p)
            with cols[i % 3]:
                if img:
                    st.image(img, caption=p.name, use_container_width=True)

    # ---------- Additional Reports ----------
    st.subheader("Additional Reports")
    rep = data["reports"]
    if rep["cluster_compactness"] is not None:
        st.markdown("**Cluster compactness** (lower is tighter)")
        st.dataframe(rep["cluster_compactness"], use_container_width=True, height=250)
    if rep["embedding_similarity"] is not None:
        st.markdown("**Embedding similarity** (same vs. different volunteer)")
        st.dataframe(rep["embedding_similarity"], use_container_width=True, height=250)

    # ---------- Misclassification Audit ----------
    st.subheader("Misclassification Audit")
    if data["mis_html"] is not None:
        url = data["mis_html"].as_uri()
        st.markdown(f"[Open misclassified gallery (HTML)]({url})")

        # Inline preview: rewrite relative links to absolute file:// paths
        with open(data["mis_html"], "r", encoding="utf-8") as f:
            html_content = f.read()

        root_dir = (data["meta_dir"].parent).resolve()  # project ROOT

        def to_abs_uri(rel: str) -> str:
            rel_clean = rel.replace("\\", "/")
            if rel_clean.startswith(("http://", "https://", "data:", "file://")):
                return rel_clean
            abs_path = (root_dir / rel_clean).resolve()
            if abs_path.exists():
                return abs_path.as_uri()
            alt_path = (data["meta_dir"] / rel_clean).resolve()
            if alt_path.exists():
                return alt_path.as_uri()
            return rel  # leave as-is if not found

        # 1) src="..." and href="..."
        def rewrite_src_href(m):
            attr = m.group(1)
            quoted = m.group(2)
            q = quoted[0]
            body = quoted[1:-1]
            new = to_abs_uri(body)
            return f"{attr}={q}{new}{q}"

        html_fixed = re.sub(
            r'(src|href)=(".*?"|\'.*?\')',
            rewrite_src_href,
            html_content,
            flags=re.IGNORECASE,
        )

        # 2) CSS url(...)
        def rewrite_css_url(m):
            inner = m.group(1).strip(" '\"")
            new = to_abs_uri(inner)
            return f'url("{new}")'

        html_fixed = re.sub(
            r"url\(([^)]+)\)", rewrite_css_url, html_fixed, flags=re.IGNORECASE
        )

        st.markdown('<span class="badge">Inline preview</span>', unsafe_allow_html=True)
        st.components.v1.html(html_fixed, height=800, scrolling=True)
    else:
        st.caption("Run `miscls_gallery.py` to generate `metadata/misclassified.html`.")

    st.markdown("---")
    st.caption(
        "SBBrasil TrainSheets — local dashboard. All outputs are generated offline from your artifacts."
    )


if __name__ == "__main__":
    main()
